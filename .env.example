# LLM API Configuration
# Choose one of the following LLM providers

# GitHub Models (FREE for Copilot users!) - RECOMMENDED
# Get token from: https://github.com/settings/tokens
# Scopes needed: repo, read:user
GITHUB_TOKEN=your_github_personal_access_token_here
GITHUB_MODEL=gpt-4o-mini

# OpenAI Configuration (Requires payment)
OPENAI_API_KEY=your_openai_api_key_here
OPENAI_MODEL=gpt-4-turbo-preview

# Anthropic Claude Configuration (Requires payment)
# ANTHROPIC_API_KEY=your_anthropic_api_key_here
# ANTHROPIC_MODEL=claude-3-sonnet-20240229

# LLM Provider (github, openai, or anthropic)
LLM_PROVIDER=github

# Repository Configuration
REPO_URL=https://github.com/janjakovacevic/SakilaProject
REPO_LOCAL_PATH=./data/SakilaProject

# Token Limits
MAX_TOKENS_PER_CHUNK=6000
MAX_OUTPUT_TOKENS=2000

# Analysis Configuration
INCLUDE_FILE_EXTENSIONS=.java,.xml,.properties,.md
EXCLUDE_DIRECTORIES=.git,target,bin,.idea,.vscode,node_modules
